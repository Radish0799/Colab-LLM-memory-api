{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Um0nRVeZBwgL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install flask flask-cors transformers sentence-transformers pyngrok python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any, Tuple\n",
        "import pickle\n",
        "import logging\n",
        "from flask import Flask, request, jsonify, render_template_string\n",
        "from flask_cors import CORS\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import time"
      ],
      "metadata": {
        "id": "jmn-HsZTBz9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5Cy2FROB5Ou",
        "outputId": "c4543166-0323-44a4-c771-de1ebcfc104d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "your_ngrok_authtoken = \"your_ngrok_authtoken\""
      ],
      "metadata": {
        "id": "jkZRwgWWS_Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "Qg8nmCk0B-PQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MemoryManager:\n",
        "  def __init__(self, drive_path=\"/content/drive/MyDrive/memory_api_data\"):\n",
        "    self.drive_path = drive_path\n",
        "    self.memory_file = os.path.join(drive_path, \"conversations.json\")\n",
        "    self.embeddings_file = os.path.join(drive_path, \"embeddings.pkl\")\n",
        "\n",
        "    # ディレクトリが存在することを確認する\n",
        "    os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "    # load model\n",
        "    logger.info(\"PLaMo-embedding-1bモデルをロードしています...\")\n",
        "    self.model = SentenceTransformer('pfnet/plamo-embedding-1b', trust_remote_code=True)\n",
        "    logger.info(\"モデルのロードが完了しました\")\n",
        "\n",
        "    # 記憶データをロードする\n",
        "    self.conversations = self._load_conversations()\n",
        "    self.embeddings = self._load_embeddings()\n",
        "\n",
        "    # 類似度のしきい値\n",
        "    self.similarity_threshold = 0.7\n",
        "    self.max_memory_items = 100\n",
        "\n",
        "  def _load_conversations(self) -> List[Dict]:\n",
        "    \"\"\"会話履歴をロードする\"\"\"\n",
        "    if os.path.exists(self.memory_file):\n",
        "      try:\n",
        "        with open(self.memory_file, 'r', encoding='utf-8') as f:\n",
        "          return json.load(f)\n",
        "      except Exception as e:\n",
        "        logger.error(f\"会話履歴のロードに失敗しました: {e}\")\n",
        "        return []\n",
        "    return []\n",
        "\n",
        "  def _save_conversations(self):\n",
        "    \"\"\"会話履歴を保存する\"\"\"\n",
        "    try:\n",
        "      with open(self.memory_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(self.conversations, f, ensure_ascii=False, indent=2)\n",
        "    except Exception as e:\n",
        "      logger.error(f\"会話履歴の保存に失敗しました: {e}\")\n",
        "\n",
        "  def _load_embeddings(self) -> List[np.ndarray]:\n",
        "    \"\"\"埋め込みベクトルをロードする\"\"\"\n",
        "    if os.path.exists(self.embeddings_file):\n",
        "      try:\n",
        "        with open(self.embeddings_file, 'rb') as f:\n",
        "          return pickle.load(f)\n",
        "      except Exception as e:\n",
        "        logger.error(f\"埋め込みベクトルのロードに失敗しました: {e}\")\n",
        "        return []\n",
        "    return []\n",
        "\n",
        "  def _save_embeddings(self):\n",
        "    \"\"\"埋め込みベクトルを保存する\"\"\"\n",
        "    try:\n",
        "      with open(self.embeddings_file, 'wb') as f:\n",
        "        pickle.dump(self.embeddings, f)\n",
        "    except Exception as e:\n",
        "      logger.error(f\"埋め込みベクトルの保存に失敗しました: {e}\")\n",
        "\n",
        "  def add_conversation(self, user_input: str, assistant_response: str, user_id: str = \"default\"):\n",
        "    \"\"\"\n",
        "    新しい会話履歴を追加する\n",
        "    Args:\n",
        "      user_input: ユーザーの入力\n",
        "      assistant_response: 応答\n",
        "      user_id: ユーザーID\n",
        "    \"\"\"\n",
        "    conversation = {\n",
        "      \"id\": len(self.conversations),\n",
        "      \"user_id\": user_id,\n",
        "      \"user_input\": user_input,\n",
        "      \"assistant_response\": assistant_response,\n",
        "      \"timestamp\": datetime.now().isoformat(),\n",
        "    }\n",
        "\n",
        "    # 埋め込みベクトルを計算する\n",
        "    try:\n",
        "      embedding = self.model.encode(user_input)\n",
        "\n",
        "      self.conversations.append(conversation)\n",
        "      self.embeddings.append(embedding)\n",
        "\n",
        "      # メモリの最大数を超えた場合は古い履歴を削除する\n",
        "      if len(self.conversations) > self.max_memory_items:\n",
        "        self.conversations = self.conversations[-self.max_memory_items:]\n",
        "        self.embeddings = self.embeddings[-self.max_memory_items:]\n",
        "\n",
        "      # Driveに保存する\n",
        "      self._save_conversations()\n",
        "      self._save_embeddings()\n",
        "\n",
        "      logger.info(f\"新しい会話履歴を追加しました: {conversation['id']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "      logger.error(f\"会話履歴の追加に失敗しました: {e}\")\n",
        "\n",
        "  def find_similar_conversations(self, query: str, user_id: str = \"default\", top_k: int = 3) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    類似する会話履歴を検索する\n",
        "    Args:\n",
        "      query: 検索テキスト\n",
        "      user_id: ユーザーID\n",
        "      top_k: 上位K件の結果を返す\n",
        "    Returns:\n",
        "      類似する会話履歴のリスト\n",
        "    \"\"\"\n",
        "    if not self.conversations or not self.embeddings:\n",
        "      return []\n",
        "\n",
        "    try:\n",
        "      # クエリの埋め込みベクトルを計算する\n",
        "      query_embedding = self.model.encode(query).reshape(1, -1)\n",
        "\n",
        "      # ユーザーの会話履歴をフィルタリングする\n",
        "      user_conversations = []\n",
        "      user_embeddings = []\n",
        "\n",
        "      for i, conv in enumerate(self.conversations):\n",
        "        if conv.get(\"user_id\", \"default\") == user_id:\n",
        "          user_conversations.append(conv)\n",
        "          user_embeddings.append(self.embeddings[i])\n",
        "\n",
        "      if not user_conversations:\n",
        "        return []\n",
        "\n",
        "      # 類似度を計算する\n",
        "      user_embeddings_matrix = np.vstack(user_embeddings)\n",
        "      similarities = cosine_similarity(query_embedding, user_embeddings_matrix)[0]\n",
        "\n",
        "      # 類似度がしきい値を超えた会話を探す\n",
        "      similar_indices = []\n",
        "      for i, sim in enumerate(similarities):\n",
        "        if sim >= self.similarity_threshold:\n",
        "          similar_indices.append((i, sim))\n",
        "\n",
        "      # 類似度でソートする\n",
        "      similar_indices.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "      # 上位top_k件の結果を返す\n",
        "      results = []\n",
        "      for i, sim in similar_indices[:top_k]:\n",
        "        conv = user_conversations[i].copy()\n",
        "        conv[\"similarity\"] = float(sim)\n",
        "        results.append(conv)\n",
        "\n",
        "      logger.info(f\"見つかった類似対話記録: {len(results)}件\")\n",
        "      return results\n",
        "\n",
        "    except Exception as e:\n",
        "      logger.error(f\"類似対話記録の検索に失敗しました: {e}\")\n",
        "      return []\n",
        "\n",
        "  def get_conversation_stats(self) -> Dict:\n",
        "    \"\"\"対話の統計情報を取得する\"\"\"\n",
        "    return {\n",
        "      \"total_conversations\": len(self.conversations),\n",
        "      \"total_embeddings\": len(self.embeddings),\n",
        "      \"similarity_threshold\": self.similarity_threshold,\n",
        "      \"max_memory_items\": self.max_memory_items\n",
        "    }"
      ],
      "metadata": {
        "id": "pSu4ZZ69CDg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "memory_manager = MemoryManager()\n",
        "\n",
        "@app.route('/api/health', methods=['GET'])\n",
        "def health_check():\n",
        "  \"\"\"health\"\"\"\n",
        "  return jsonify({\n",
        "    \"status\": \"healthy\",\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"service\": \"Memory API\"\n",
        "  })\n",
        "\n",
        "@app.route('/api/stats', methods=['GET'])\n",
        "def get_stats():\n",
        "  \"\"\"統計情報を取得する\"\"\"\n",
        "  stats = memory_manager.get_conversation_stats()\n",
        "  return jsonify(stats)\n",
        "\n",
        "@app.route('/api/query', methods=['POST'])\n",
        "def query_memory():\n",
        "  \"\"\"類似した会話履歴を検索する\"\"\"\n",
        "  try:\n",
        "    data = request.get_json()\n",
        "\n",
        "    if not data or 'query' not in data:\n",
        "      return jsonify({\"error\": \"queryパラメータが不足しています\"}), 400\n",
        "\n",
        "    query = data['query']\n",
        "    user_id = data.get('user_id', 'default')\n",
        "    top_k = data.get('top_k', 3)\n",
        "\n",
        "    # 類似した会話を探す\n",
        "    similar_conversations = memory_manager.find_similar_conversations(\n",
        "      query=query,\n",
        "      user_id=user_id,\n",
        "      top_k=top_k\n",
        "    )\n",
        "\n",
        "    response = {\n",
        "      \"query\": query,\n",
        "      \"user_id\": user_id,\n",
        "      \"found_memories\": len(similar_conversations),\n",
        "      \"has_relevant_memory\": len(similar_conversations) > 0,\n",
        "      \"memories\": similar_conversations,\n",
        "      \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    return jsonify(response)\n",
        "\n",
        "  except Exception as e:\n",
        "    logger.error(f\"記憶の検索に失敗しました: {e}\")\n",
        "    return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/add', methods=['POST'])\n",
        "def add_memory():\n",
        "  \"\"\"会話履歴を追加する\"\"\"\n",
        "  try:\n",
        "    data = request.get_json()\n",
        "\n",
        "    if not data or 'user_input' not in data or 'assistant_response' not in data:\n",
        "      return jsonify({\"error\": \"必要なパラメータが不足しています\"}), 400\n",
        "\n",
        "    user_input = data['user_input']\n",
        "    assistant_response = data['assistant_response']\n",
        "    user_id = data.get('user_id', 'default')\n",
        "\n",
        "    # 会話履歴を追加する\n",
        "    memory_manager.add_conversation(\n",
        "      user_input=user_input,\n",
        "      assistant_response=assistant_response,\n",
        "      user_id=user_id\n",
        "    )\n",
        "\n",
        "    response = {\n",
        "      \"status\": \"success\",\n",
        "      \"message\": \"会話履歴が追加されました\",\n",
        "      \"user_id\": user_id,\n",
        "      \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    return jsonify(response)\n",
        "\n",
        "  except Exception as e:\n",
        "    logger.error(f\"記憶の追加に失敗しました: {e}\")\n",
        "    return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "def run_flask_app():\n",
        "  app.run(host='0.0.0.0', port=5000, debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5ICRlDaR7rd",
        "outputId": "f7b39fe5-c1e5-4b17-b514-91e8e778a3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name pfnet/plamo-embedding-1b. Creating a new one with mean pooling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  ngrok.set_auth_token(your_ngrok_authtoken)\n",
        "\n",
        "  # Flaskをバックグラウンドで起動\n",
        "  flask_thread = threading.Thread(target=run_flask_app)\n",
        "  flask_thread.daemon = True\n",
        "  flask_thread.start()\n",
        "\n",
        "  # Flaskが起動するのを待つ\n",
        "  time.sleep(5)\n",
        "\n",
        "  # ngrokトンネルを開始\n",
        "  try:\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f\"API_URL: {public_url}\")\n",
        "    print(f\"クエリAPI: {public_url}/api/query\")\n",
        "    print(f\"追加API: {public_url}/api/add\")\n",
        "    print(f\"統計API: {public_url}/api/stats\")\n",
        "    print(f\"health: {public_url}/api/health\")\n",
        "\n",
        "    # サービスを稼働させ続ける\n",
        "    print(\"\\nサービスが起動しました\")\n",
        "    try:\n",
        "      while True:\n",
        "        time.sleep(1)\n",
        "    except KeyboardInterrupt:\n",
        "      print(\"\\nサービスを停止中...\")\n",
        "      ngrok.disconnect(public_url)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"ngrokの起動に失敗しました: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_UPMiblCwvW",
        "outputId": "b0583e3e-65d0-43ed-99d9-9aa0e97f7b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API_URL: NgrokTunnel: \"https://a729-34-105-105-239.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            "クエリAPI: NgrokTunnel: \"https://a729-34-105-105-239.ngrok-free.app\" -> \"http://localhost:5000\"/api/query\n",
            "追加API: NgrokTunnel: \"https://a729-34-105-105-239.ngrok-free.app\" -> \"http://localhost:5000\"/api/add\n",
            "統計API: NgrokTunnel: \"https://a729-34-105-105-239.ngrok-free.app\" -> \"http://localhost:5000\"/api/stats\n",
            "health: NgrokTunnel: \"https://a729-34-105-105-239.ngrok-free.app\" -> \"http://localhost:5000\"/api/health\n",
            "\n",
            "サービスが起動しました\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:31:13] \"POST /api/add HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:31:13] \"POST /api/add HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:31:13] \"POST /api/add HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:31:18] \"POST /api/query HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:31:19] \"POST /api/query HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:31:19] \"POST /api/query HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:31:23] \"GET /api/stats HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:31:26] \"GET /api/health HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:32:01] \"POST /api/query HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:32:03] \"POST /api/add HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:36:44] \"POST /api/add HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:36:44] \"POST /api/add HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:36:45] \"POST /api/add HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:37:16] \"POST /api/add HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:37:17] \"POST /api/add HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:37:17] \"POST /api/add HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:40:10] \"POST /api/query HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:40:10] \"POST /api/query HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:40:10] \"POST /api/query HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:40:27] \"POST /api/query HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:40:27] \"POST /api/query HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:40:27] \"POST /api/query HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:40:47] \"GET /api/stats HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:40:51] \"GET /api/health HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:45:53] \"POST /api/query HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Jun/2025 19:45:54] \"POST /api/add HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}